{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BundleReducer(BaseEstimator):\n",
    "    def __init__(self, \n",
    "                 reduction_type,\n",
    "                 ndimensions):\n",
    "        self.reduction_type = reduction_type # case-insensitive\n",
    "        self.ndimensions = ndimensions\n",
    "        \n",
    "    def print_ndimensions(self):\n",
    "        print(\"The number of dimensions is\", ndimensions)\n",
    "        \n",
    "    def impute(self, X):\n",
    "        imputer = SimpleImputer()\n",
    "        self.data_imp_ = imputer.fit_transform(X)\n",
    "    \n",
    "    # fit and transform in either nmf or pca\n",
    "    def fit(self, X):\n",
    "        clf = self.reduction_type.lower();\n",
    "        \n",
    "        if clf == \"nmf\":\n",
    "            self.clf_ = NMF(n_components=self.ndimensions, init='random', random_state=0)\n",
    "        elif clf == \"pca\" :\n",
    "            self.clf_ = PCA(n_components=self.ndimensions)\n",
    "            \n",
    "        self.model_ =  self.clf_.fit_transform(self.data_imp_)\n",
    "        self.components_ = self.clf_.components_\n",
    "       \n",
    "        return self\n",
    "\n",
    "            \n",
    "    def reconstruct(self): \n",
    "       \n",
    "        check_is_fitted(self, 'components_')\n",
    "        self.recon_ = self.clf_.inverse_transform(self.model_)\n",
    "\n",
    "    # takes aver values for each bundles \n",
    "    def plot_comparison(self):\n",
    "        fig, ax = plt.subplots();\n",
    "        mean = np.mean(self.recon_, axis = 0);\n",
    "        data_mean = np.mean(self.data_imp_, axis = 0);\n",
    "        ax.plot(mean);\n",
    "        ax.plot(data_mean);\n",
    "        \n",
    "    def reconstruction_error(self): \n",
    "\n",
    "        loss = np.zeros(len(self.data_imp_));\n",
    "        for i in range(len(self.data_imp_)):\n",
    "             loss[i] = np.sqrt(np.mean(((self.recon_[i, :])-self.data_imp_[i, :])**2))\n",
    "        return loss\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import afqinsight.datasets as ad\n",
    "ad.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ad.load_afq_data(fn_nodes= \"combined_tract_profiles.csv\", fn_subjects=\"participant_data.tsv\", \n",
    "                        unsupervised=True,return_bundle_means=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dki_fa = data.X[:, 0:1800]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-validation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from importlib import reload\n",
    "import tools \n",
    "reload (tools)\n",
    "from tools import crossvalidation\n",
    "\n",
    "X = dki_fa;\n",
    "loss = crossvalidation(X, PCA, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "loss_df = pd.DataFrame(loss.T, columns = [2,4,8,16,32,64,128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_plot = sns.catplot( data=loss_df, kind='violin')\n",
    "pca_plot.set_xlabels('number of dimensions')\n",
    "pca_plot.set_ylabels('error in 5 folds croxx-validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA for each bundle\n",
    "X1 = np.reshape(X, (641, 18, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ARC_L','ARC_R','ATR_L','ATR_R','CGC_L','CGC_R','CST_L','CST_R', 'FA','FP','IFO_L', 'IFO_R','ILF_L','ILF_R','SLF_L','SLF_R','UNC_L','UNC_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvinbundle(bundle, dcom, num_fold):\n",
    "    ind_bun = labels.index(bundle)\n",
    "    arr= np.zeros((641, 100))\n",
    "    arr = X1[:, ind_bun, :]\n",
    "    loss = crossvalidation(arr, dcom, num_fold)\n",
    "    loss_df_arc_l = pd.DataFrame(loss_arc_l.T, columns = [2,4,8,16,32,64])\n",
    "    pca_plot = sns.catplot( data=loss_df_arc_l, kind='violin')\n",
    "    pca_plot.set_xlabels('number of dimensions')\n",
    "    pca_plot.set_ylabels('error in {} folds croxx-validation for {}'.format(num_fold, bundle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvinbundle('IFO_L', NMF, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvinbundle('IFO_L', PCA, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvinbundle('ARC_L', PCA, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_arc_l= crossvalidation(arc_l, PCA, 2);\n",
    "loss_df_arc_l = pd.DataFrame(loss_arc_l.T, columns = [2,4,8,16,32,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_plot = sns.catplot( data=loss_df_arc_l, kind='violin')\n",
    "pca_plot.set_xlabels('number of dimensions')\n",
    "pca_plot.set_ylabels('error in 2 folds croxx-validation for arc_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = BundleReducer(\"pca\", 3)\n",
    "\n",
    "br.impute(arc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br.fit(X1[:, :, 0])\n",
    "rec_arc_l = br.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br.plot_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA with 3 dimensions (dki_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br3 = BundleReducer(\"pca\", 3)\n",
    "br3.impute(dki_fa)\n",
    "br3.fit(dki_fa)\n",
    "rec_dki_fa = br3.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br3.plot_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA with 4 dimensions (dki_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br4 = BundleReducer(\"pca\", 4)\n",
    "br4.impute(dki_fa)\n",
    "br4.fit(dki_fa)\n",
    "rec_dki_fa = br4.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br4.plot_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_br4 = br4.reconstruction_error()\n",
    "np.mean(error_br4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(br4.data_imp_[1, :])\n",
    "plt.plot(br4.recon_[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((br4.data_imp_[1, :]-br4.recon_[1, :])**2)) # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br5 = BundleReducer(\"pca\", 5)\n",
    "br5.impute(dki_fa)\n",
    "br5.fit(dki_fa)\n",
    "rec_dki_fa_5 = br5.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 dimensions\n",
    "br6 = BundleReducer(\"pca\", 6)\n",
    "br6.impute(dki_fa)\n",
    "br6.fit(dki_fa)\n",
    "rec_dki_fa_6 = br6.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 dimensions\n",
    "br7 = BundleReducer(\"pca\", 7)\n",
    "br7.impute(dki_fa)\n",
    "br7.fit(dki_fa)\n",
    "rec_dki_fa_7 = br7.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 dimension\n",
    "br8 = BundleReducer(\"pca\", 8)\n",
    "br8.impute(dki_fa)\n",
    "br8.fit(dki_fa)\n",
    "rec_dki_fa_8 = br8.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 dimension\n",
    "br10 = BundleReducer(\"pca\", 10)\n",
    "br10.impute(dki_fa)\n",
    "br10.fit(dki_fa)\n",
    "rec_dki_fa_10 = br10.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_bundles(data_imp, data_recon, sample):\n",
    "    \n",
    "    diff_bundle = np.zeros(18)\n",
    "    for i in range(18):\n",
    "        ind = 100*i;\n",
    "        ind1 = ind +100;\n",
    "        diff_bundle[i] = np.sqrt(np.mean((data_imp[sample, ind:ind1]-data_recon[sample, ind:ind1])**2))\n",
    "        \n",
    "    diff = np.zeros([641, 18])\n",
    "    \n",
    "    return diff_bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_3 = np.zeros([641, 18])\n",
    "for i in range(641):\n",
    "    diff_3[i, :] = diff_bundles(br3.data_imp_, br3.recon_, i)\n",
    "diff_3 = diff_3.mean(axis = 0)\n",
    "diff_4 = np.zeros([641, 18])\n",
    "for i in range(641):\n",
    "    diff_4[i, :] = diff_bundles(br4.data_imp_, br4.recon_, i)\n",
    "diff_4 = diff_4.mean(axis = 0)\n",
    "diff_5 = np.zeros([641, 18])\n",
    "for i in range(641):\n",
    "    diff_5[i, :] = diff_bundles(br5.data_imp_, br5.recon_, i)\n",
    "diff_5 = diff_5.mean(axis = 0)\n",
    "diff_6 = np.zeros([641, 18])\n",
    "for i in range(641):\n",
    "    diff_6[i, :] = diff_bundles(br6.data_imp_, br6.recon_, i)\n",
    "diff_6 = diff_6.mean(axis = 0)\n",
    "diff_7 = np.zeros([641, 18])\n",
    "for i in range(641):\n",
    "    diff_7[i, :] = diff_bundles(br7.data_imp_, br7.recon_, i)\n",
    "diff_7 = diff_7.mean(axis = 0)\n",
    "diff_8 = np.zeros([641, 18])\n",
    "for i in range(641):\n",
    "    diff_8[i, :] = diff_bundles(br8.data_imp_, br8.recon_, i)\n",
    "diff_8 = diff_8.mean(axis = 0)\n",
    "diff_10 = np.zeros([641, 18])\n",
    "for i in range(641):\n",
    "    diff_10[i, :] = diff_bundles(br10.data_imp_, br10.recon_, i)\n",
    "diff_10 = diff_10.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(100)\n",
    "n = 7;\n",
    "\n",
    "\n",
    "\n",
    "p = sns.color_palette(\"rocket\", n_colors=n)\n",
    "# 2, 3, 5, 6, 8, 10 add legend\n",
    "legend = [3, 4, 5, 6, 7, 8, 10]\n",
    "x = range(0, 18)\n",
    "labels = ['ARC_L',\n",
    " 'ARC_R',\n",
    " 'ATR_L',\n",
    " 'ATR_R',\n",
    " 'CGC_L',\n",
    " 'CGC_R',\n",
    " 'CST_L',\n",
    " 'CST_R',\n",
    " 'FA',\n",
    " 'FP',\n",
    " 'IFO_L',\n",
    " 'IFO_R',\n",
    " 'ILF_L',\n",
    " 'ILF_R',\n",
    " 'SLF_L',\n",
    " 'SLF_R',\n",
    " 'UNC_L',\n",
    " 'UNC_R']\n",
    "scaled_data = [diff_3.T, diff_4.T, diff_5.T, diff_6.T, diff_7.T, diff_8.T, diff_10.T]\n",
    "for dd in range(n):\n",
    "    plt.plot(scaled_data[dd], color=p[dd], label = legend[dd])\n",
    "    plt.legend();\n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    plt.xlabel('bundles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
